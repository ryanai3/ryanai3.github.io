[{"authors":null,"categories":null,"date":1530158400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1530158400,"objectID":"18d05a63a1c8d7ed973cc51838494e41","permalink":"https://ryanai3.github.io/privacy/","publishdate":"2018-06-28T00:00:00-04:00","relpermalink":"/privacy/","section":"","summary":"\u0026hellip;","tags":null,"title":"Privacy Policy","type":"page"},{"authors":["GA Cushen"],"categories":null,"date":1441080000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1441080000,"objectID":"5cec0ce6e082b377c504bc66cdf990c5","permalink":"https://ryanai3.github.io/publication/person-re-identification/","publishdate":"2015-09-01T00:00:00-04:00","relpermalink":"/publication/person-re-identification/","section":"publication","summary":"Person re-identification is a critical security task for recognizing a person across spatially disjoint sensors. Previous work can be computationally intensive and is mainly based on low-level cues extracted from RGB data and implemented on a PC for a fixed sensor network (such as traditional CCTV). We present a practical and efficient framework for mobile devices (such as smart phones and robots) where high-level semantic soft biometrics are extracted from RGB and depth data. By combining these cues, our approach attempts to provide robustness to noise, illumination, and minor variations in clothing. This mobile approach may be particularly useful for the identification of persons in areas ill-served by fixed sensors or for tasks where the sensor position and direction need to dynamically adapt to a target. Results on the BIWI dataset are preliminary but encouraging. Further evaluation and demonstration of the system will be available on our website.","tags":[],"title":"A Person Re-Identification System For Mobile Devices","type":"publication"},{"authors":["GA Cushen","MS Nixon"],"categories":null,"date":1372651200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1372651200,"objectID":"caae70970030052c8f733b2ca8421a2b","permalink":"https://ryanai3.github.io/publication/clothing-search/","publishdate":"2013-07-01T00:00:00-04:00","relpermalink":"/publication/clothing-search/","section":"publication","summary":"We present a mobile visual clothing search system whereby a smart phone user can either choose a social networking photo or take a new photo of a person wearing clothing of interest and search for similar clothing in a retail database. From the query image, the person is detected, clothing is segmented, and clothing features are extracted and quantized. The information is sent from the phone client to a server, where the feature vector of the query image is used to retrieve similar clothing products from online databases. The phone's GPS location is used to re-rank results by retail store location. State of the art work focuses primarily on the recognition of a diverse range of clothing offline and pays little attention to practical applications. Evaluated on a challenging dataset, the system is relatively fast and achieves promising results.","tags":[],"title":"Mobile visual clothing search","type":"publication"}]